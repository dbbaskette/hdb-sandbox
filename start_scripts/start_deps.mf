line = 10
LOG=/var/log/startup_script.log

NO_COLOR=\x1b[0m
OK_COLOR=\x1b[32;01m
ERROR_COLOR=\x1b[31;01m
WARN_COLOR=\x1b[33;01m

OK_STRING=[$(OK_COLOR)  OK  $(NO_COLOR)]
ERROR_STRING=[$(ERROR_COLOR)ERRORS$(NO_COLOR)]
WARN_STRING=[$(WARN_COLOR)WARNINGS$(NO_COLOR)]

ECHO=echo -e
ECHO_ERR=printf 'Starting%-50s$(ERROR_STRING)\n' "$1"
ECHO_WARN=printf 'Starting%-50s$(WARN_STRING)\n' "$1"
ECHO_OK=printf 'Starting%-50s$(OK_STRING)\n' "$1"
CAT=cat

define colorized
@$2 1>$(LOG) 2> "temp $1.log" || touch temp.errors;
@$3;
@if test -e "temp $1.errors"; then ($(ECHO_ERR) | tee -a $(LOG)) && ($(CAT) "temp $1.log" $4 | tee -a $(LOG)); elif test -s "temp $1.log"; then ($(ECHO_WARN) && $(CAT) "temp $1.log") | tee -a $(LOG); else $(ECHO_OK) | tee -a $(LOG); fi;
@$(RM) -f "temp $1.errors" "temp $1.log";
endef

all: Startup Ambari Others

Startup: Ambari HDFS YARN Zookeeper Hive_Metastore WebHCat Zeppelin Spark ## Oozie Atlas Flume Ranger
Ambari: ambari_server ambari_agent 
Others: HBase Storm

HDFS: namenode datanode nfsportpap hdfsnfs
YARN: resourcemanager yarnhistoryserver mapredhistoryserver nodemanagers
HBase: hbase_master hbase_regionservers hbase_stargate hbase_thrift
Zookeeper: zookeeper
Hive_Metastore: mysql hive hive2
Storm: nimbus supervisor stormui stormdrpc stormlogview # stormrest
WebHCat: webhcat
Tez: # tez
Oozie: oozie
Atlas: atlas
Kafka: kafka
Spark: spark
Zeppelin: zeppelin
Flume: flume
Ranger: Ranger-admin Ranger-usersync


spark: HDFS
	$(call colorized,\
		Spark,\
		su - spark -c '/usr/hdp/current/spark-historyserver/sbin/start-history-server.sh',\
		sleep 10,)



Ranger-admin: 
	$(call colorized,\
		Ranger-admin,\
		su  ranger -c 'env JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.85.x86_64 /usr/bin/ranger-admin-start',\
		sleep 10,)

Ranger-usersync: Ranger-admin
	$(call colorized,\
                Ranger-usersync,\
                su ranger -c 'env JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.85.x86_64 /usr/bin/ranger-usersync-start',\
                sleep 10,)

flume:
	$(call colorized,\
                Flume, \
                echo "STARTED">/var/run/flume/ambari-state.txt,\
                sleep 10,)

zeppelin: HDFS Spark
	$(call colorized,\
                Zepplin, \
                su - zeppelin -c '/usr/hdp/current/zeppelin-server/lib/bin/zeppelin-daemon.sh start >> /var/log/zeppelin/zeppelin-setup.log &> /dev/null',\
                sleep 10,)


atlas:
	$(call colorized,\
                atlas,\
                su - atlas -c 'source /etc/atlas/conf/atlas-env.sh ; /usr/hdp/current/atlas-server/bin/atlas_start.py --port 21000',\
                sleep 5,\
                /var/log/atlas/application.log,)


postgresql:
	$(call colorized,\
		Postgre SQL, \
		@/etc/init.d/postgresql start,\
		sleep 10,)

# ==== HDFS ====

namenode: postgresql
	$(call colorized,\
		name node, \
		su - hdfs -c 'export HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec && /usr/hdp/current/hadoop-client/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start namenode',\
		sleep 5,\
		/var/log/hadoop/hdfs/hadoop-hdfs-namenode-*.log)

datanode: postgresql
	$(call colorized,\
		data node, \
		su - hdfs -c 'export HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec && /usr/hdp/current/hadoop-client/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start datanode',\
		sleep 5,\
		/var/log/hadoop/hdfs/hadoop-hdfs-datanode-*.log)
	@su - hdfs -c"hdfs dfsadmin -safemode leave"


secondary_namenode: postgresql
	$(call colorized,\
		secondary name node, \
		su - hdfs -c 'export HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec && /usr/hdp/current/hadoop-client/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start secondarynamenode',\
		sleep 5,\
		/var/log/hadoop/hdfs/hadoop-hdfs-secondarynamenode-*.log)

nfsportpap: namenode datanode
	$(call colorized,\
		NFS portmap, \
		export HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec && /usr/hdp/current/hadoop-client/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start portmap,\
		sleep 5,\
		/var/log/hadoop/root/hadoop-root-portmap-sandbox.hortonworks.com.log)

hdfsnfs: namenode datanode
	$(call colorized,\
		Hdfs nfs, \
		export HADOOP_PRIVILEGED_NFS_LOG_DIR=/var/log/hadoop/root HADOOP_PRIVILEGED_NFS_PID_DIR=/var/run/hadoop/root HADOOP_PRIVILEGED_NFS_USER=hdfs HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec && /var/lib/ambari-agent/ambari-sudo.sh -H -E /usr/hdp/current/hadoop-client/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start nfs3,\
		sleep 5,\
		/var/log/hadoop/root/hadoop-root-nfs3-sandbox.hortonworks.com.log)


# ==== YARN ====
resourcemanager: postgresql HDFS
	$(call colorized,\
		resource manager, \
		su - yarn -c'export HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec && /usr/hdp/current/hadoop-yarn-client/sbin/yarn-daemon.sh --config /etc/hadoop/conf start resourcemanager',\
		sleep 25)


yarnhistoryserver: postgresql HDFS
	$(call colorized,\
		yarn history server, \
		su - yarn -c'export HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec && /usr/hdp/current/hadoop-yarn-client/sbin/yarn-daemon.sh --config /etc/hadoop/conf start historyserver',\
		sleep 5)

mapredhistoryserver: postgresql HDFS
	$(call colorized,\
		mapred history server, \
		until su - hdfs -c 'hdfs dfsadmin -safemode get' | grep OFF > /dev/null; do sleep 1;done; su - mapred -c'export HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec && /usr/hdp/current/hadoop-mapreduce-historyserver/sbin/mr-jobhistory-daemon.sh --config /etc/hadoop/conf start historyserver',\
		sleep 5)


nodemanagers: postgresql HDFS
	$(call colorized,\
		node manager, \
		su - yarn -c 'ulimit -c unlimited; export HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec && /usr/hdp/current/hadoop-yarn-client/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager',\
		sleep 5)


# ==== HBase ====

hbase_master: postgresql zookeeper
	$(call colorized,\
		hbase master, \
		su - hbase -c "hbase-daemon.sh --config /etc/hbase/conf start master",\
		sleep 25,\
		/var/log/hbase/hbase-hbase-master-*.log)

hbase_stargate: postgresql hbase_master
	$(call colorized,\
		hbase stargate, \
		su -l hbase -c "hbase-daemon.sh start rest -p 60080",\
		true,\
		/var/log/hbase/hbase-hbase-rest-*.log)

hbase_thrift: postgresql hbase_master
	$(call colorized,\
		hbase thrift, \
		su -l hbase -c "hbase-daemon.sh start thrift",\
		true,\
		/var/log/hbase/hbase-hbase-rest-*.log)

hbase_regionservers: hbase_master
	$(call colorized,\
		hbase regionservers, \
		su -l hbase -c "hbase-daemon.sh --config /etc/hbase/conf start regionserver",\
		sleep 5,\
		/var/log/hbase/hbase-hbase-regionserver-*.log)

# ==== Hive ====

mysql:
	$(call colorized,\
		mysql, \
		/etc/init.d/mysqld start,\
		true)

hive: HDFS postgresql mysql
	$(call colorized,\
		hive server, \
		su - hive -c 'env HADOOP_HOME=/usr/hdp/current/hadoop-client JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk.x86_64 /var/lib/ambari-agent/tmp/start_metastore_script /var/log/hive/hive.out /var/log/hive/hive.log /var/run/hive/hive.pid /usr/hdp/current/hive-metastore/conf/conf.server /var/log/hive', true,\
		/var/log/hive/hive.log)

hive2: HDFS hive
	$(call colorized,\
		Hiveserver2, \
		su - hive -c 'env JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk.x86_64 /var/lib/ambari-agent/tmp/start_hiveserver2_script /var/log/hive/hive-server2.out /var/log/hive/hive-server2.log /var/run/hive/hive-server.pid /usr/hdp/current/hive-server2/conf/conf.server /var/log/hive',true,\
		/var/log/hive/hive-server2.log)

# ==== Storm ====

nimbus: Zookeeper YARN
	$(call colorized,\
		Storm nimbus, \
				su - storm -c 'env JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk.x86_64 PATH=$PATH:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/bin storm nimbus > /var/log/storm/nimbus.out 2>&1 &'; sleep 10; su - storm -c'pgrep -f "^java.+backtype.storm.daemon.nimbus$" && pgrep -f "^java.+backtype.storm.daemon.nimbus$" > /var/run/storm/nimbus.pid',true)

supervisor: Zookeeper stormui YARN
	$(call colorized,\
		Storm supervisor, \
		su - storm -c 'env JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk.x86_64 PATH=$PATH:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/bin storm supervisor > /var/log/storm/supervisor.out 2>&1 &'; sleep 10; su - storm -c'pgrep -f "^java.+backtype.storm.daemon.supervisor$" && pgrep -f "^java.+backtype.storm.daemon.supervisor$" > /var/run/storm/supervisor.pid',true)

stormui: Zookeeper nimbus stormlogview YARN
	$(call colorized,\
		Storm ui, \
		su - storm -c 'env JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk.x86_64 PATH=$PATH:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/bin storm ui > /var/log/storm/ui.out 2>&1 &'; sleep 10; su - storm -c 'pgrep -f "^java.+backtype.storm.ui.core$" && pgrep -f "^java.+backtype.storm.ui.core$" > /var/run/storm/ui.pid',true)

stormdrpc: Zookeeper nimbus YARN
	$(call colorized,\
		Storm DRPC, \
		su - storm -c 'env JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk.x86_64 PATH=$PATH:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/bin storm drpc > /var/log/storm/drpc.log &'; sleep 10; su - storm -c 'pgrep -f "^java.+backtype.storm.daemon.drpc$" && pgrep -f "^java.+backtype.storm.daemon.drpc$" > /var/run/storm/drpc.pid',true)

stormlogview: Zookeeper stormdrpc YARN
	$(call colorized,\
		Storm Logview, \
				su - storm -c 'env JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk.x86_64 PATH=$PATH:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/bin storm logviewer > /var/log/storm/logviewer.log &'; sleep 10; su - storm -c'pgrep -f "^java.+backtype.storm.daemon.logviewer$" && pgrep -f "^java.+backtype.storm.daemon.logviewer$" > /var/run/storm/logviewer.pid',true)

#stormrest: supervisor YARN
#	$(call colorized,\
#               Storm Rest server,\
#               su - storm -c 'env JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk.x86_64 PATH=$PATH:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/bin java -jar /usr/hdp/current/storm/contrib/storm-rest/`ls /usr/hdp/current/storm/contrib/storm-rest | grep -wE storm-rest-[0-9.-]+\.jar` server /etc/storm/conf/config.yaml > /var/log/storm/restapi.log &'; sleep 10; su - storm -c 'pgrep -f "/usr/jdk64/jdk1.7.0_45/bin/java -jar /usr/hdp/current/storm/contrib/storm-rest/`ls /usr/hdp/current/storm/contrib/storm-rest | grep -wE storm-rest-[0-9.-]+\.jar` server" && pgrep -f "/usr/jdk64/jdk1.7.0_45/bin/java -jar /usr/hdp/current/storm/contrib/storm-rest/`ls /usr/hdp/current/storm/contrib/storm-rest | grep -wE storm-rest-[0-9.-]+\.jar` server" > /var/run/storm/restapi.pid', true)


# ==== Single services ====

zookeeper: namenode
	$(call colorized,\
		zookeeper nodes, \
		su - zookeeper -c "source /etc/zookeeper/conf/zookeeper-env.sh ; env ZOOCFGDIR=/etc/zookeeper/conf ZOOCFG=zoo.cfg /usr/hdp/current/zookeeper-server/bin/zkServer.sh start 2>/dev/null; sleep 10",\
		true)


#tez: namenode
#	$(call colorized,\
#		tez node, \
#		su - tez -c "/usr/hdp/current/tez/sbin/tez-daemon.sh start ampoolservice",\
#		true)
	

webhcat: hive HDFS
	$(call colorized,\
		webhcat server, \
		su -l hcat -c "env HADOOP_HOME=/usr/hdp/current/hadoop-client /usr/hdp/current/hive-webhcat/sbin/webhcat_server.sh start", true\
		, /var/log/webhcat/webhcat.log)


oozie: namenode
	$(call colorized,\
		Oozie, \
		su - oozie -c "cd /var/log/oozie; /usr/hdp/current/oozie-server/bin/oozie-start.sh 2>/dev/null", true\
		,\
		/var/log/oozie/oozie.log)


falcon: HDFS Oozie
	$(call colorized,\
		Falcon, \
		su - falcon -c'env HADOOP_HOME=/usr/hdp/current/hadoop-client JAVA_HOME=/usr/jdk64/jdk1.7.0_45 FALCON_LOG_DIR=/var/log/falcon FALCON_PID_DIR=/var/run/falcon FALCON_DATA_DIR=/hadoop/falcon/activemq /usr/hdp/current/falcon-server/bin/falcon-start -port 15000',\
		sleep 5,)


knox-ldap:
	$(call colorized,\
		Knox ldap, \
		su - knox -c "/usr/hdp/current/knox-server/bin/ldap.sh start",\
		sleep 2,)
  

knox-gateway: HDFS WebHCat Oozie knox-ldap
	$(call colorized,\
		Knox gateway, \
		su - knox -c "/usr/hdp/current/knox-server/bin/gateway.sh start",\
		sleep 2,)


# ==== Ambari ====

ambari_server: 
	$(call colorized,\
		Ambari server, \
		ambari-server start,\
		sleep 5, )


ambari_agent: ambari_server
	$(call colorized,\
		Ambari agent, \
		ambari-agent start,true)


